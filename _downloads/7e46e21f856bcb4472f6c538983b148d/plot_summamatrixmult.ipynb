{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n# Distributed Matrix Multiplication - SUMMA\nThis example shows how to use the :py:class:`pylops_mpi.basicoperators.MPIMatrixMult`\noperator with ``kind='summa'`` to perform matrix-matrix multiplication between \na matrix $\\mathbf{A}$ distributed in 2D blocks across a square process \ngrid and matrices $\\mathbf{X}$ and $\\mathbf{Y}$ distributed in 2D \nblocks across the same grid. Similarly, the adjoint operation can be performed \nwith a matrix $\\mathbf{Y}$ distributed in the same fashion as matrix \n$\\mathbf{X}$.\n\nNote that whilst the different blocks of matrix $\\mathbf{A}$ are directly\nstored in the operator on different ranks, the matrices $\\mathbf{X}$ and\n$\\mathbf{Y}$ are effectively represented by 1-D :py:class:`pylops_mpi.DistributedArray`\nobjects where the different blocks are flattened and stored on different ranks.\nNote that to optimize communications, the ranks are organized in a square grid and\nblocks of $\\mathbf{A}$ and $\\mathbf{X}$ are systematically broadcast\nacross different ranks during computation - see below for details.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import math\nimport numpy as np\nfrom mpi4py import MPI\nfrom matplotlib import pyplot as plt\n\nimport pylops_mpi\nfrom pylops import Conj\nfrom pylops_mpi.basicoperators.MatrixMult import \\\n    local_block_split, MPIMatrixMult, active_grid_comm\n\nplt.close(\"all\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We set the seed such that all processes can create the input matrices filled\nwith the same random number. In practical applications, such matrices will be\nfilled with data that is appropriate to the use-case.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "np.random.seed(42)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We are now ready to create the input matrices for our distributed matrix\nmultiplication example. We need to set up:\n\n- Matrix $\\mathbf{A}$ of size $N \\times K$ (the left operand)\n- Matrix $\\mathbf{X}$ of size $K \\times M$ (the right operand)  \n- The result will be $\\mathbf{Y} = \\mathbf{A} \\mathbf{X}$ of size \n$N \\times M$\n\nWe create here global test matrices with sequential values for easy verification:\n\n- Matrix A: Each element $A_{i,j} = i \\cdot K + j$ (row-major ordering)\n- Matrix X: Each element $X_{i,j} = i \\cdot M + j$\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "N, M, K = 6, 6, 6\nA_shape, x_shape, y_shape = (N, K), (K, M), (N, M)\n\nA_data = np.arange(int(A_shape[0] * A_shape[1])).reshape(A_shape)\nx_data = np.arange(int(x_shape[0] * x_shape[1])).reshape(x_shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "For distributed computation, we arrange processes in a square grid of size\n$P' \\times P'$ where $P' = \\sqrt{P}$ and $P$ is the total \nnumber of MPI processes. Each process will own a block of each matrix \naccording to this 2D grid layout.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "base_comm = MPI.COMM_WORLD\ncomm, rank, row_id, col_id, is_active = active_grid_comm(base_comm, N, M)\nprint(f\"Process {base_comm.Get_rank()} is {'active' if is_active else 'inactive'}\")\n\np_prime = math.isqrt(comm.Get_size())\nprint(f\"Process grid: {p_prime} x {p_prime} = {comm.Get_size()} processes\")\n\nif rank == 0:\n    print(f\"Global matrix A shape: {A_shape} (N={A_shape[0]}, K={A_shape[1]})\")\n    print(f\"Global matrix X shape: {x_shape} (K={x_shape[0]}, M={x_shape[1]})\")\n    print(f\"Expected Global result Y shape: ({A_shape[0]}, {x_shape[1]}) = (N, M)\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Next we must determine which block of each matrix each process should own.\n\nThe 2D block distribution requires:\n\n- Process at grid position $(i,j)$ gets block \n  $\\mathbf{A}[i_{start}:i_{end}, j_{start}:j_{end}]$\n- Block sizes are approximately $\\lceil N/P' \\rceil \\times \\lceil K/P' \\rceil$\n  with edge processes handling remainder\n\n.. raw:: html\n\n  <div style=\"text-align: left; font-family: monospace; white-space: pre;\">\n  <b>Example: 2x2 Process Grid with 6x6 Matrices</b>\n\n  Matrix A (6x6):                    Matrix X (6x6):\n  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510      \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n  \u2502  0  1  2  \u2502  3  4  5  \u2502      \u2502  0  1  2  \u2502  3  4  5  \u2502\n  \u2502  6  7  8  \u2502  9 10 11  \u2502      \u2502  6  7  8  \u2502  9 10 11  \u2502\n  \u2502 12 13 14  \u2502 15 16 17  \u2502      \u2502 12 13 14  \u2502 15 16 17  \u2502\n  \u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524      \u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n  \u2502 18 19 20  \u2502 21 22 23  \u2502      \u2502 18 19 20  \u2502 21 22 23  \u2502\n  \u2502 24 25 26  \u2502 27 28 29  \u2502      \u2502 24 25 26  \u2502 27 28 29  \u2502\n  \u2502 30 31 32  \u2502 33 34 35  \u2502      \u2502 30 31 32  \u2502 33 34 35  \u2502\n  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518      \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n\n  Process (0,0): A[0:3, 0:3], X[0:3, 0:3]\n  Process (0,1): A[0:3, 3:6], X[0:3, 3:6]  \n  Process (1,0): A[3:6, 0:3], X[3:6, 0:3]\n  Process (1,1): A[3:6, 3:6], X[3:6, 3:6]\n  </div>\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "A_slice = local_block_split(A_shape, rank, comm)\nx_slice = local_block_split(x_shape, rank, comm)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Extract the local portion of each matrix for this process\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "A_local = A_data[A_slice]\nx_local = x_data[x_slice]\n\nprint(f\"Process {rank}: A_local shape {A_local.shape}, X_local shape {x_local.shape}\")\nprint(f\"Process {rank}: A slice {A_slice}, X slice {x_slice}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We are now ready to create the SUMMA :py:class:`pylops_mpi.basicoperators.MPIMatrixMult`\noperator and the input matrix $\\mathbf{X}$\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "Aop = MPIMatrixMult(A_local, M, base_comm=comm, kind=\"summa\", dtype=A_local.dtype)\n\nx_dist = pylops_mpi.DistributedArray(\n    global_shape=(K * M),\n    local_shapes=comm.allgather(x_local.shape[0] * x_local.shape[1]),\n    base_comm=comm,\n    partition=pylops_mpi.Partition.SCATTER,\n    dtype=x_local.dtype)\nx_dist[:] = x_local.flatten()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We can now apply the forward pass $\\mathbf{y} = \\mathbf{Ax}$ (which\neffectively implements a distributed matrix-matrix multiplication\n$Y = \\mathbf{AX}$). Note $\\mathbf{Y}$ is distributed in the same\nway as the input $\\mathbf{X}$ in a block-block fashion.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "y_dist = Aop @ x_dist"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Next we apply the adjoint pass $\\mathbf{x}_{adj} = \\mathbf{A}^H \\mathbf{x}$\n(which effectively implements a distributed summa matrix-matrix multiplication\n$\\mathbf{X}_{adj} = \\mathbf{A}^H \\mathbf{X}$). Note that\n$\\mathbf{X}_{adj}$ is again distributed in the same way as the input\n$\\mathbf{X}$ in a block-block fashion.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "xadj_dist = Aop.H @ y_dist"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Finally, we show that the SUMMA :py:class:`pylops_mpi.basicoperators.MPIMatrixMult`\noperator can be combined with any other PyLops-MPI operator. We are going to\napply here a conjugate operator to the output of the matrix multiplication.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "Dop = Conj(dims=(A_local.shape[0], x_local.shape[1]))\nDBop = pylops_mpi.MPIBlockDiag(ops=[Dop, ])\nOp = DBop @ Aop\ny1 = Op @ x_dist"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}