{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n# Distributed Matrix Multiplication\nThis example shows how to use the :py:class:`pylops_mpi.basicoperators.MPIMatrixMult`\noperator to perform matrix-matrix multiplication between a matrix $\\mathbf{A}$\nblocked over rows (i.e., blocks of rows are stored over different ranks) and a\nmatrix $\\mathbf{X}$ blocked over columns (i.e., blocks of columns are\nstored over different ranks), with equal number of row and column blocks.\nSimilarly, the adjoint operation can be peformed with a matrix $\\mathbf{Y}$\nblocked in the same fashion of matrix $\\mathbf{X}$.\n\nNote that whilst the different blocks of the matrix $\\mathbf{A}$ are directly\nstored in the operator on different ranks, the matrix $\\mathbf{X}$ is\neffectively represented by a 1-D :py:class:`pylops_mpi.DistributedArray` where\nthe different blocks are flattened and stored on different ranks. Note that to\noptimize communications, the ranks are organized in a 2D grid and some of the\nrow blocks of $\\mathbf{A}$ and column blocks of $\\mathbf{X}$ are\nreplicated across different ranks - see below for details.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from matplotlib import pyplot as plt\nimport math\nimport numpy as np\nfrom mpi4py import MPI\n\nfrom pylops_mpi import DistributedArray, Partition\nfrom pylops_mpi.basicoperators.MatrixMult import MPIMatrixMult\n\nplt.close(\"all\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We set the seed such that all processes can create the input matrices filled\nwith the same random number. In practical application, such matrices will be\nfilled with data that is appropriate that is appropriate the use-case.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "np.random.seed(42)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We are now ready to create the input matrices $\\mathbf{A}$ of size\n$M \\times k$ $\\mathbf{A}$ of size and $\\mathbf{A}$ of size\n$K \\times N$.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "N, K, M = 4, 4, 4\nA = np.random.rand(N * K).astype(dtype=np.float32).reshape(N, K)\nX = np.random.rand(K * M).astype(dtype=np.float32).reshape(K, M)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The processes are now arranged in a $P' \\times P'$ grid,\nwhere $P$ is the total number of processes.\n\nWe define\n\n\\begin{align}P' = \\bigl \\lceil \\sqrt{P} \\bigr \\rceil\\end{align}\n\nand the replication factor\n\n\\begin{align}R = \\bigl\\lceil \\tfrac{P}{P'} \\bigr\\rceil.\\end{align}\n\nEach process is therefore assigned a pair of coordinates\n$(r,c)$ within this grid:\n\n\\begin{align}r = \\left\\lfloor \\frac{\\mathrm{rank}}{P'} \\right\\rfloor,\n   \\quad\n   c = \\mathrm{rank} \\bmod P'.\\end{align}\n\nFor example, when $P = 4$ we have $P' = 2$, giving a 2\u00d72 layout:\n\n.. raw:: html\n\n   <div style=\"text-align: center; font-family: monospace; white-space: pre;\">\n  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n  \u2502 Rank 0     \u2502 Rank 1     \u2502\n  \u2502 (r=0, c=0) \u2502 (r=0, c=1) \u2502\n  \u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n  \u2502 Rank 2     \u2502 Rank 3     \u2502\n  \u2502 (r=1, c=0) \u2502 (r=1, c=1) \u2502\n  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n   </div>\n\nThis is obtained by invoking the\n:func:`pylops_mpi.basicoperators.MPIMatrixMult.active_grid_comm` method, which is also\nresponsible to identify any rank that should be deactivated (if the number\nof rows of the operator or columns of the input/output matrices are smaller\nthan the row or columm ranks.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "base_comm = MPI.COMM_WORLD\ncomm, rank, row_id, col_id, is_active = MPIMatrixMult.active_grid_comm(base_comm, N, M)\nprint(f\"Process {base_comm.Get_rank()} is {'active' if is_active else 'inactive'}\")\nif not is_active: exit(0)\n\n# Create sub\u2010communicators\np_prime = math.isqrt(comm.Get_size())\nrow_comm = comm.Split(color=row_id, key=col_id)  # all procs in same row\ncol_comm = comm.Split(color=col_id, key=row_id)  # all procs in same col"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "At this point we divide the rows and columns of $\\mathbf{A}$ and\n$\\mathbf{X}$, respectively, such that each rank ends up with:\n\n - $A_{p} \\in \\mathbb{R}^{\\text{my_own_rows}\\times K}$\n - $X_{p} \\in \\mathbb{R}^{K\\times \\text{my_own_cols}}$\n\n.. raw:: html\n\n  <div style=\"text-align: left; font-family: monospace; white-space: pre;\">\n  <b>Matrix A (4 x 4):</b>\n  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n  \u2502 a11 a12 a13 a14 \u2502 <- Rows 0\u20131 (Process Grid Row 0)\n  \u2502 a21 a22 a23 a24 \u2502\n  \u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n  \u2502 a41 a42 a43 a44 \u2502 <- Rows 2\u20133 (Process Grid Row 1)\n  \u2502 a51 a52 a53 a54 \u2502\n  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n  </div>\n\n.. raw:: html\n\n  <div style=\"text-align: left; font-family: monospace; white-space: pre;\">\n  <b>Matrix X (4 x 4):</b>\n  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n  \u2502 b11 b12 \u2502 b13 b14 \u2502 <- Cols 0\u20131 (Process Grid Col 0), Cols 2\u20133 (Process Grid Col 1)\n  \u2502 b21 b22 \u2502 b23 b24 \u2502\n  \u2502 b31 b32 \u2502 b33 b34 \u2502\n  \u2502 b41 b42 \u2502 b43 b44 \u2502\n  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n  </div>\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "blk_rows = int(math.ceil(N / p_prime))\nblk_cols = int(math.ceil(M / p_prime))\n\nrs = col_id * blk_rows\nre = min(N, rs + blk_rows)\nmy_own_rows = max(0, re - rs)\n\ncs = row_id * blk_cols\nce = min(M, cs + blk_cols)\nmy_own_cols = max(0, ce - cs)\n\nA_p, X_p = A[rs:re, :].copy(), X[:, cs:ce].copy()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We are now ready to create the :py:class:`pylops_mpi.basicoperators.MPIMatrixMult`\noperator and the input matrix $\\mathbf{X}$\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "Aop = MPIMatrixMult(A_p, M, base_comm=comm, dtype=\"float32\")\n\ncol_lens = comm.allgather(my_own_cols)\ntotal_cols = np.sum(col_lens)\nx = DistributedArray(global_shape=K * total_cols,\n                     local_shapes=[K * col_len for col_len in col_lens],\n                     partition=Partition.SCATTER,\n                     mask=[i % p_prime for i in range(comm.Get_size())],\n                     base_comm=comm,\n                     dtype=\"float32\")\nx[:] = X_p.flatten()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We can now apply the forward pass $\\mathbf{y} = \\mathbf{Ax}$ (which effectively\nimplements a distributed matrix-matrix multiplication $Y = \\mathbf{AX}$)\nNote $\\mathbf{Y}$ is distributed in the same way as the input\n$\\mathbf{X}$.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "y = Aop @ x"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Next we apply the adjoint pass $\\mathbf{x}_{adj} = \\mathbf{A}^H \\mathbf{x}$\n(which effectively implements a distributed matrix-matrix multiplication\n$\\mathbf{X}_{adj} = \\mathbf{A}^H \\mathbf{X}$). Note that\n$\\mathbf{X}_{adj}$ is again distributed in the same way as the input\n$\\mathbf{X}$.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "xadj = Aop.H @ y"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "To conclude we verify our result against the equivalent serial version of\nthe operation by gathering the resulting matrices in rank0 and reorganizing\nthe returned 1D-arrays into 2D-arrays.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Local benchmarks\ny = y.asarray(masked=True)\ncol_counts = [min(blk_cols, M - j * blk_cols) for j in range(p_prime)]\ny_blocks = []\noffset = 0\nfor cnt in col_counts:\n    block_size = N * cnt\n    y_block = y[offset: offset + block_size]\n    if len(y_block) != 0:\n        y_blocks.append(\n            y_block.reshape(N, cnt)\n        )\n    offset += block_size\ny = np.hstack(y_blocks)\n\nxadj = xadj.asarray(masked=True)\nxadj_blocks = []\noffset = 0\nfor cnt in col_counts:\n    block_size = K * cnt\n    xadj_blk = xadj[offset: offset + block_size]\n    if len(xadj_blk) != 0:\n        xadj_blocks.append(\n            xadj_blk.reshape(K, cnt)\n        )\n    offset += block_size\nxadj = np.hstack(xadj_blocks)\n\nif rank == 0:\n    y_loc = (A @ X).squeeze()\n    xadj_loc = (A.T.dot(y_loc.conj())).conj().squeeze()\n\n    if not np.allclose(y, y_loc, rtol=1e-6):\n        print(\"FORWARD VERIFICATION FAILED\")\n        print(f'distributed: {y}')\n        print(f'expected: {y_loc}')\n    else:\n        print(\"FORWARD VERIFICATION PASSED\")\n\n    if not np.allclose(xadj, xadj_loc, rtol=1e-6):\n        print(\"ADJOINT VERIFICATION FAILED\")\n        print(f'distributed: {xadj}')\n        print(f'expected: {xadj_loc}')\n    else:\n        print(\"ADJOINT VERIFICATION PASSED\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}