{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n# Distributed Array\nThis example shows how to use the :py:class:`pylops_mpi.DistributedArray`.\nThis class provides a way to distribute arrays across multiple processes in\na parallel computing environment.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from matplotlib import pyplot as plt\nimport numpy as np\nimport pylops_mpi\n\nplt.close(\"all\")\nnp.random.seed(42)\n\n# Defining the global shape of the distributed array\nglobal_shape = (10, 5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let's start by defining the\nclass with the input parameters ``global_shape``,\n``partition``, and ``axis``. Here's an example implementation of the class with ``axis=0``.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "arr = pylops_mpi.DistributedArray(global_shape=global_shape,\n                                  partition=pylops_mpi.Partition.SCATTER,\n                                  axis=0)\n# Filling the local arrays\narr[:] = np.arange(arr.local_shape[0] * arr.local_shape[1] * arr.rank,\n                   arr.local_shape[0] * arr.local_shape[1] * (arr.rank + 1)).reshape(arr.local_shape)\npylops_mpi.plot_distributed_array(arr)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Below is an implementation to show how the global array is distributed along\nthe second axis.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "arr = pylops_mpi.DistributedArray(global_shape=global_shape,\n                                  partition=pylops_mpi.Partition.SCATTER,\n                                  axis=1)\n# Filling the local arrays\narr[:] = np.arange(arr.local_shape[0] * arr.local_shape[1] * arr.rank,\n                   arr.local_shape[0] * arr.local_shape[1] * (arr.rank + 1)).reshape(arr.local_shape)\npylops_mpi.plot_distributed_array(arr)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "To convert a random NumPy array into a ``pylops_mpi.DistributedArray``,\nyou can use the ``to_dist`` classmethod. This method allows you to distribute\nthe array across multiple processes for parallel computation.\nBelow is an example implementation depicting the same.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "n = global_shape[0] * global_shape[1]\n# Array to be distributed\narray = np.arange(n) / float(n)\narr1 = pylops_mpi.DistributedArray.to_dist(x=array.reshape(global_shape), axis=1)\narray = array / 2.0\narr2 = pylops_mpi.DistributedArray.to_dist(x=array.reshape(global_shape), axis=1)\n# plot local arrays\npylops_mpi.plot_local_arrays(arr1, \"Distributed Array - 1\", vmin=0, vmax=1)\npylops_mpi.plot_local_arrays(arr2, \"Distributed Array - 2\", vmin=0, vmax=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Element-wise Addition** - Each process operates on its local portion of\nthe array and adds the corresponding elements together.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "sum_arr = arr1 + arr2\npylops_mpi.plot_local_arrays(sum_arr, \"Addition\", vmin=0, vmax=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Element-wise Subtraction** - Each process operates on its local portion\nof the array and subtracts the corresponding elements together.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "diff_arr = arr1 - arr2\npylops_mpi.plot_local_arrays(diff_arr, \"Subtraction\", vmin=0, vmax=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Element-wise Multiplication** - Each process operates on its local portion\nof the array and multiplies the corresponding elements together.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "mult_arr = arr1 * arr2\npylops_mpi.plot_local_arrays(mult_arr, \"Multiplication\", vmin=0, vmax=1)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}